{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2b63c9-1bed-4ccc-9e90-93f3255be566",
   "metadata": {},
   "source": [
    "## 긍정/부정 리뷰 분별"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aedb049-9556-446c-b03f-2eb5f80aa1c1",
   "metadata": {},
   "source": [
    "### 와 근데 이 라이브러리는 성능이 너무 별로다 <br>\n",
    "### GPT 돌리기로 정하는 쪽으로..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3cf1364-b803-4bae-8525-1ed2d6d5031e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d8e180-d21e-4747-a5f1-677a4e2de23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc74bc20-6b99-47db-8f86-bb2b23e31f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감성 분석 결과가 C:\\Users\\USER\\Desktop\\5_6\\core_pj\\data\\crawlingOrNogada\\review_sentiment_analysis.xlsx에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# NLTK의 VADER lexicon 다운로드\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = r\"C:\\Users\\USER\\Desktop\\5_6\\core_pj\\data\\crawlingOrNogada\\combined_reviews.xlsx\"\n",
    "\n",
    "# 엑셀 파일 로드\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# VADER 감성 분석 도구 초기화\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 리뷰에 대한 감성 분석 수행\n",
    "def analyze_sentiment(review):\n",
    "    scores = sia.polarity_scores(review)\n",
    "    compound_score = scores['compound']\n",
    "    if compound_score >= 0.5:\n",
    "        return 2  # 매우 긍정적\n",
    "    elif 0 < compound_score < 0.5:\n",
    "        return 1  # 긍정적\n",
    "    elif -0.5 < compound_score <= 0:\n",
    "        return -1  # 부정적\n",
    "    else:\n",
    "        return -2  # 매우 부정적\n",
    "\n",
    "# NaN 값을 빈 문자열로 대체하고 float 값을 문자열로 변환\n",
    "df['리뷰'] = df['리뷰'].fillna('').astype(str)\n",
    "\n",
    "# 감성 점수 컬럼 추가\n",
    "df['감성 점수'] = df['리뷰'].apply(analyze_sentiment)\n",
    "\n",
    "# 결과 저장\n",
    "output_file_path = r\"C:\\Users\\USER\\Desktop\\5_6\\core_pj\\data\\crawlingOrNogada\\review_sentiment_analysis.xlsx\"\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"감성 분석 결과가 {output_file_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f14cc6-a8f0-4aa9-9b8b-2ab584e9b41a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b515cc0-b886-4ae8-bab4-f6d6ee5d4ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc5d547-5259-467e-8e1c-c81d9ad11e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ac2e6a-6877-4e0c-8536-cab78641087a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 30.7/43.8 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.8/43.8 kB 533.0 kB/s eta 0:00:00\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Downloading tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.1/9.1 MB 33.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 3.5/9.1 MB 44.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.7/9.1 MB 45.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.9/9.1 MB 46.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 41.5 MB/s eta 0:00:00\n",
      "Downloading torch-2.3.0-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "   ---------------------------------------- 0.0/159.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/159.8 MB 87.7 MB/s eta 0:00:02\n",
      "    --------------------------------------- 3.4/159.8 MB 54.0 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 5.0/159.8 MB 45.2 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 7.4/159.8 MB 42.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 8.7/159.8 MB 43.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 11.3/159.8 MB 43.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 13.3/159.8 MB 46.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 13.6/159.8 MB 43.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 13.6/159.8 MB 43.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 13.6/159.8 MB 43.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 13.6/159.8 MB 43.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 14.8/159.8 MB 26.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 16.7/159.8 MB 26.2 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 18.3/159.8 MB 25.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 20.4/159.8 MB 25.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 22.2/159.8 MB 25.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 24.2/159.8 MB 43.7 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 26.3/159.8 MB 46.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 28.2/159.8 MB 46.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 30.5/159.8 MB 46.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 32.3/159.8 MB 46.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 33.5/159.8 MB 43.7 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 35.4/159.8 MB 43.7 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 36.6/159.8 MB 40.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 39.5/159.8 MB 40.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 41.3/159.8 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 43.1/159.8 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 45.5/159.8 MB 50.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 47.4/159.8 MB 50.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 49.3/159.8 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 51.3/159.8 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 52.9/159.8 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 54.4/159.8 MB 43.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 56.2/159.8 MB 43.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 57.7/159.8 MB 43.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 58.5/159.8 MB 38.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 60.4/159.8 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 62.8/159.8 MB 40.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 64.5/159.8 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 67.2/159.8 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 69.1/159.8 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 71.1/159.8 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 72.7/159.8 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 75.2/159.8 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 76.1/159.8 MB 43.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 77.7/159.8 MB 38.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 80.6/159.8 MB 43.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 83.0/159.8 MB 43.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 85.1/159.8 MB 40.9 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 87.0/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 89.1/159.8 MB 50.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 91.2/159.8 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 93.2/159.8 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 95.5/159.8 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 97.8/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 100.0/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 102.0/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 103.9/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 105.9/159.8 MB 50.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 107.8/159.8 MB 46.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 109.7/159.8 MB 43.7 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 111.8/159.8 MB 46.9 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 114.0/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 116.1/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 118.1/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 120.8/159.8 MB 46.9 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 123.5/159.8 MB 46.9 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 125.0/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 127.9/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 130.2/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 132.7/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 133.9/159.8 MB 43.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 135.1/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 137.2/159.8 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 139.0/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 141.4/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 144.0/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 146.1/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 148.0/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 151.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 153.8/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  155.9/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.6/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.3/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 159.8/159.8 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "   ---------------------------------------- 0.0/401.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 401.3/401.3 kB 26.1 MB/s eta 0:00:00\n",
      "Downloading mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "   ---------------------------------------- 0.0/228.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/228.5 MB 26.1 MB/s eta 0:00:09\n",
      "    --------------------------------------- 3.1/228.5 MB 32.6 MB/s eta 0:00:07\n",
      "    --------------------------------------- 5.2/228.5 MB 36.6 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 7.4/228.5 MB 39.3 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 9.8/228.5 MB 39.3 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 11.0/228.5 MB 36.4 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 13.4/228.5 MB 40.9 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 15.7/228.5 MB 38.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 17.6/228.5 MB 38.5 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 19.6/228.5 MB 38.6 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 21.5/228.5 MB 43.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 23.4/228.5 MB 40.9 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 25.8/228.5 MB 43.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 27.9/228.5 MB 43.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 29.5/228.5 MB 43.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 30.8/228.5 MB 40.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 31.9/228.5 MB 38.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 33.0/228.5 MB 36.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 34.4/228.5 MB 32.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 36.1/228.5 MB 32.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 38.7/228.5 MB 34.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 40.2/228.5 MB 34.4 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 42.9/228.5 MB 40.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 45.0/228.5 MB 46.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 45.5/228.5 MB 43.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 48.4/228.5 MB 43.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 51.2/228.5 MB 46.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 53.9/228.5 MB 50.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 55.3/228.5 MB 50.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 58.4/228.5 MB 54.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 59.8/228.5 MB 46.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 62.2/228.5 MB 50.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 63.2/228.5 MB 43.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 63.5/228.5 MB 36.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 64.6/228.5 MB 36.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 66.3/228.5 MB 34.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 67.2/228.5 MB 31.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 67.3/228.5 MB 27.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 67.5/228.5 MB 23.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 68.0/228.5 MB 21.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 69.7/228.5 MB 21.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 71.3/228.5 MB 21.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 73.4/228.5 MB 21.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 73.9/228.5 MB 23.4 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 76.2/228.5 MB 23.4 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 78.2/228.5 MB 38.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 81.0/228.5 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 82.7/228.5 MB 43.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 83.1/228.5 MB 36.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 83.4/228.5 MB 32.7 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 83.9/228.5 MB 29.7 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 84.7/228.5 MB 28.5 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 86.4/228.5 MB 28.4 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 88.5/228.5 MB 27.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 90.1/228.5 MB 27.3 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 91.5/228.5 MB 25.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 92.5/228.5 MB 24.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 94.3/228.5 MB 32.8 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 96.2/228.5 MB 36.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 98.3/228.5 MB 34.4 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 100.4/228.5 MB 38.6 MB/s eta 0:00:04\n",
      "   ----------------- --------------------- 102.1/228.5 MB 43.7 MB/s eta 0:00:03\n",
      "   ----------------- --------------------- 104.2/228.5 MB 46.9 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 105.9/228.5 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 108.4/228.5 MB 46.7 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 110.4/228.5 MB 43.7 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 110.8/228.5 MB 36.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 112.6/228.5 MB 36.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 114.6/228.5 MB 36.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 115.9/228.5 MB 34.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 117.6/228.5 MB 34.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 119.9/228.5 MB 32.7 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 123.2/228.5 MB 46.7 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 124.0/228.5 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 124.2/228.5 MB 34.6 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 124.6/228.5 MB 29.8 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 126.1/228.5 MB 31.2 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 127.9/228.5 MB 31.2 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 130.4/228.5 MB 32.7 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 132.5/228.5 MB 29.8 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 134.5/228.5 MB 38.6 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 136.6/228.5 MB 46.7 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 138.7/228.5 MB 43.7 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 141.0/228.5 MB 43.7 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 143.3/228.5 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 145.9/228.5 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 147.9/228.5 MB 46.7 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 149.4/228.5 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 150.7/228.5 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 152.3/228.5 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 154.8/228.5 MB 38.5 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 156.5/228.5 MB 36.4 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 158.5/228.5 MB 36.4 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 159.9/228.5 MB 38.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 160.6/228.5 MB 34.4 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 162.8/228.5 MB 36.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 164.7/228.5 MB 34.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 166.6/228.5 MB 36.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 168.1/228.5 MB 34.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 168.6/228.5 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 171.0/228.5 MB 38.6 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 173.0/228.5 MB 36.4 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 175.0/228.5 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 177.1/228.5 MB 36.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 179.6/228.5 MB 43.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 181.3/228.5 MB 43.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 183.5/228.5 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 185.0/228.5 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 185.9/228.5 MB 38.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 186.2/228.5 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 186.9/228.5 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 189.2/228.5 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 191.2/228.5 MB 31.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 193.5/228.5 MB 29.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 195.3/228.5 MB 32.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 197.8/228.5 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 199.8/228.5 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 202.1/228.5 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 204.6/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 207.1/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 209.8/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 211.7/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 213.2/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 215.3/228.5 MB 46.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 217.6/228.5 MB 46.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 218.9/228.5 MB 46.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 222.0/228.5 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  224.8/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  227.2/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  228.5/228.5 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 228.5/228.5 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 2.6/3.5 MB 56.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.5/3.5 MB 56.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 37.7 MB/s eta 0:00:00\n",
      "Downloading tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 286.4/286.4 kB 17.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "   ---------------------------------------- 0.0/287.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 287.3/287.3 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 1.9/2.2 MB 61.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 47.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tbb, intel-openmp, safetensors, mkl, torch, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.1 intel-openmp-2021.4.0 mkl-2021.4.0 safetensors-0.4.3 tbb-2021.12.0 tokenizers-0.19.1 torch-2.3.0 transformers-4.41.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb280778-f500-4c24-92f9-2cd8fbee59db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9b99e1979e464a9ed96e939915b0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a559283edaaa4441a9bd8f52425685e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ab22c16dab4d6bb0aa71be038281cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb0704ea96f4a029fba8a2ff38efd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (531) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m리뷰\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m리뷰\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 감성 점수 컬럼 추가\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m감성 점수\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m리뷰\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(analyze_sentiment)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 결과 저장\u001b[39;00m\n\u001b[0;32m     34\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUSER\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m5_6\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcore_pj\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcrawlingOrNogada\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mreview_sentiment_analysis_huggingface.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_sentiment\u001b[39m(review):\n\u001b[1;32m---> 15\u001b[0m     result \u001b[38;5;241m=\u001b[39m sentiment_analysis(review)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m     label \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m     score \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:156\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03mClassify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    155\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,)\n\u001b[1;32m--> 156\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m _legacy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1243\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1236\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1237\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         )\n\u001b[0;32m   1241\u001b[0m     )\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1250\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1249\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1250\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\base.py:1150\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1149\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1150\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1151\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:187\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    186\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:991\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    989\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 991\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[0;32m    992\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    993\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    994\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    995\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    996\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    997\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    998\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    999\u001b[0m )\n\u001b[0;32m   1000\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:803\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    801\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 803\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[0;32m    806\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:141\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[1;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[0;32m    137\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m position_ids\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand_as(input_ids)  \u001b[38;5;66;03m# (bs, max_seq_length)\u001b[39;00m\n\u001b[0;32m    139\u001b[0m position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m input_embeds \u001b[38;5;241m+\u001b[39m position_embeddings  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    142\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[0;32m    143\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (531) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = r\"C:\\Users\\USER\\Desktop\\5_6\\core_pj\\data\\crawlingOrNogada\\combined_reviews.xlsx\"\n",
    "\n",
    "# 엑셀 파일 로드\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Hugging Face 감성 분석 파이프라인 로드\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# 리뷰에 대한 감성 분석 수행\n",
    "def analyze_sentiment(review):\n",
    "    result = sentiment_analysis(review)[0]\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    if label == 'POSITIVE' and score >= 0.9:\n",
    "        return 2  # 매우 긍정적\n",
    "    elif label == 'POSITIVE':\n",
    "        return 1  # 긍정적\n",
    "    elif label == 'NEGATIVE' and score >= 0.9:\n",
    "        return -2  # 매우 부정적\n",
    "    else:\n",
    "        return -1  # 부정적\n",
    "\n",
    "# NaN 값을 빈 문자열로 대체하고 float 값을 문자열로 변환\n",
    "df['리뷰'] = df['리뷰'].fillna('').astype(str)\n",
    "\n",
    "# 감성 점수 컬럼 추가\n",
    "df['감성 점수'] = df['리뷰'].apply(analyze_sentiment)\n",
    "\n",
    "# 결과 저장\n",
    "output_file_path = r\"C:\\Users\\USER\\Desktop\\5_6\\core_pj\\data\\crawlingOrNogada\\review_sentiment_analysis_huggingface.xlsx\"\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"감성 분석 결과가 {output_file_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d20e7b-f11a-48b3-981c-2ab10440cfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa83777-fbfe-4774-9755-73773318f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  상품명\n",
      "0     검은콩 캐슈넛 닭살볶음 세트\n",
      "1           닭살커리볶음 세트\n",
      "2         대파듬뿍두부조림 세트\n",
      "3            돼지고기찜 세트\n",
      "4   두부구이 버섯데리야끼 볶음 세트\n",
      "..                ...\n",
      "58       코다리살 감자조림 세트\n",
      "59       통들깨밥&제육볶음 세트\n",
      "60         포크토마토스튜 세트\n",
      "61        당플랜 소고기 볶음밥\n",
      "62       당플랜 닭가슴살 볶음밥\n",
      "\n",
      "[63 rows x 1 columns]\n",
      "중복 없는 상품명이 C:/Users/USER/Desktop/5_6/core_pj/data/crawlingOrNogada/reviewGoodBad2.xlsx에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_path = r'C:/Users/USER/Desktop/5_6/core_pj/data/crawlingOrNogada/combined_reviews.xlsx'\n",
    "\n",
    "# 엑셀 파일 로드\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 상품명 칼럼의 중복 없는 값들 가져오기\n",
    "unique_products = df['상품명'].unique()\n",
    "\n",
    "# DataFrame으로 변환\n",
    "unique_products_df = pd.DataFrame(unique_products, columns=['상품명'])\n",
    "\n",
    "# 결과 출력\n",
    "print(unique_products_df)\n",
    "\n",
    "# 중복 없는 값들을 새로운 엑셀 파일로 저장\n",
    "output_file_path = r'C:/Users/USER/Desktop/5_6/core_pj/data/crawlingOrNogada/reviewGoodBad2.xlsx'\n",
    "unique_products_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"중복 없는 상품명이 {output_file_path}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76727833-4159-4e47-bef6-15541215a7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
